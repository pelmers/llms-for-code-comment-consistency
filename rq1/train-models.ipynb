{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:00:38.776974Z",
     "iopub.status.busy": "2022-12-10T22:00:38.776497Z",
     "iopub.status.idle": "2022-12-10T22:00:38.795199Z",
     "shell.execute_reply": "2022-12-10T22:00:38.794079Z",
     "shell.execute_reply.started": "2022-12-10T22:00:38.776887Z"
    }
   },
   "outputs": [],
   "source": [
    "# Necesssary global constants\n",
    "# max length of code gen comes from config.n_positions\n",
    "MAX_LENGTH = 3000\n",
    "DISCARD_TOO_LONG = False\n",
    "BATCH_SIZE = 16\n",
    "N_EPOCHS = 1\n",
    "LEARNING_RATE = 1e-5\n",
    "REPO_URL = 'https://github.com/pelmers/llms-for-code-comment-consistency.git'\n",
    "USE_DEEPSPEED = False\n",
    "\n",
    "# 'codebert' or 'codegen'\n",
    "MODEL_TYPE = 'codegen'\n",
    "# model sizes are 350M, 2B, 6B, 16B (for codegen only)\n",
    "MODEL_SIZE = '350M'\n",
    "# If true, freeze the base model and only train the classifier head\n",
    "FREEZE_BASE_MODEL = False\n",
    "# If true, then we tune the positive threshold to maximize weighted f1 score, since in reality there are more negatives than positives\n",
    "# If false, then the positive threshold is always 0.5\n",
    "TUNE_THRESHOLD = True\n",
    "\n",
    "LOAD_MODEL = False\n",
    "LOAD_MODEL_F1_OR_PREC = 'f1'\n",
    "SAVE_CHECKPOINTS = False\n",
    "SAVE_BEST = True\n",
    "SAVE_CHECKPOINT_INTERVAL = 4\n",
    "USE_WANDB = True\n",
    "SAVE_ARTIFACTS_WANDB = True\n",
    "WANDB_KEY = '1a0427f55873ebb00be03054c1dc8e4fee78a637'\n",
    "\n",
    "# Folder of train.json, valid.json, test.json, relative to this file, can be in a .tar.gz that extracts to the full folder name\n",
    "DATA_FOLDER = 'data/deepjit_summary_data'\n",
    "# Support for an extras.json with extra training data we can shuffle into each epoch\n",
    "# Useful as data augmentation because of data imbalance\n",
    "USE_EXTRAS_FILE = False\n",
    "\n",
    "REQUIRE_CUDA = True\n",
    "# Set debug to true for local testing (avoid logging, smaller dataset, no checkpoints, etc.)\n",
    "DEBUG = True\n",
    "\n",
    "# After training on DATA_FOLDER, also evaluate on ADDITIONAL_TEST_FILES\n",
    "ADDITIONAL_TEST_FILES = []\n",
    "\n",
    "# If running as a script, allow os.environ to overwrite these options\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    for k, v in os.environ.items():\n",
    "        if k in globals():\n",
    "            # First check if v is a boolean or a number and convert to the right type\n",
    "            if v.lower() == 'true':\n",
    "                v = True\n",
    "            elif v.lower() == 'false':\n",
    "                v = False\n",
    "            elif v.isnumeric():\n",
    "                v = int(v)\n",
    "            # Or a float\n",
    "            elif '.' in v and v.replace('.', '').isnumeric():\n",
    "                v = float(v)\n",
    "            # Or a list\n",
    "            elif v.startswith('[') and v.endswith(']'):\n",
    "                v = v[1:-1].split(',')\n",
    "                v = [a.strip() for a in v]\n",
    "            globals()[k] = v\n",
    "\n",
    "RUN_LANGUAGE = 'java'\n",
    "RUN_LANGUAGE = 'go' if 'go' in DATA_FOLDER.lower() else RUN_LANGUAGE\n",
    "RUN_LANGUAGE = 'py' if 'python' in DATA_FOLDER.lower() else RUN_LANGUAGE\n",
    "RUN_LANGUAGE = 'js' if 'javascript' in DATA_FOLDER.lower() or 'js' in DATA_FOLDER.lower() else RUN_LANGUAGE\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    BATCH_SIZE = 3\n",
    "    N_EPOCHS = 1\n",
    "    MODEL_SIZE = '350M'\n",
    "    USE_DEEPSPEED = False\n",
    "    REQUIRE_CUDA = False\n",
    "    FREEZE_BASE_MODEL = True\n",
    "\n",
    "    LOAD_MODEL = False\n",
    "    SAVE_CHECKPOINTS = False\n",
    "    SAVE_BEST = False\n",
    "    USE_WANDB = False\n",
    "\n",
    "RUN_NAME = f\"{MODEL_TYPE}_sz{MODEL_SIZE if MODEL_TYPE == 'codegen' else 'base' }\" + \\\n",
    "    f\"_bs{BATCH_SIZE}_lr{LEARNING_RATE}_len{MAX_LENGTH}_lang{RUN_LANGUAGE}\" + \\\n",
    "    (\"_disc\" if DISCARD_TOO_LONG else \"\") + \\\n",
    "    (\"_deepspd\" if USE_DEEPSPEED else \"\") + \\\n",
    "    (\"_freeze\" if FREEZE_BASE_MODEL else \"\") + \\\n",
    "    (\"_tune\" if TUNE_THRESHOLD else \"\") + \\\n",
    "    (\"_extras\" if USE_EXTRAS_FILE else \"\") + \\\n",
    "    (\"_debug\" if DEBUG else \"\")\n",
    "\n",
    "RUN_NOTES = f\"\"\"Notes:\n",
    "Dataset: {DATA_FOLDER}\n",
    "Max epochs: {N_EPOCHS}\n",
    "Load model: {LOAD_MODEL}\n",
    "\"\"\"\n",
    "\n",
    "import sys, subprocess, os\n",
    "\n",
    "# Define function x that given a command string, runs it with subprocess and streams the output\n",
    "def x(cmd):\n",
    "    return subprocess.run(cmd.split(\" \")).returncode\n",
    "\n",
    "ckpt_basename = f'ckpt_{RUN_NAME}'\n",
    "\n",
    "# The ratio of negative to positive examples in the training set before it was downsampled\n",
    "NEGATIVE_TO_POSITIVE_RATIO = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:00:38.820316Z",
     "iopub.status.busy": "2022-12-10T22:00:38.819028Z",
     "iopub.status.idle": "2022-12-10T22:00:45.473888Z",
     "shell.execute_reply": "2022-12-10T22:00:45.472780Z",
     "shell.execute_reply.started": "2022-12-10T22:00:38.820275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/ubuntu/miniconda3/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: wandb in /home/ubuntu/miniconda3/lib/python3.10/site-packages (0.15.8)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.15.9-py3-none-any.whl (2.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 65.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: transformers in /home/ubuntu/miniconda3/lib/python3.10/site-packages (4.32.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.33.0-py3-none-any.whl (7.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.6/7.6 MB 85.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib in /home/ubuntu/miniconda3/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: tokenizers in /home/ubuntu/miniconda3/lib/python3.10/site-packages (0.13.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: pathtools in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (65.5.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (1.13.0)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (3.1.30)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: PyYAML in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: setproctitle in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ubuntu/miniconda3/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Installing collected packages: wandb, transformers\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.15.8\n",
      "    Uninstalling wandb-0.15.8:\n",
      "      Successfully uninstalled wandb-0.15.8\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.32.0\n",
      "    Uninstalling transformers-4.32.0:\n",
      "      Successfully uninstalled transformers-4.32.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ecco 0.1.2 requires scikit-learn~=0.23, but you have scikit-learn 1.3.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed transformers-4.33.0 wandb-0.15.9\n"
     ]
    }
   ],
   "source": [
    "# Install pip packages\n",
    "assert x('pip install -U scikit-learn wandb transformers matplotlib tokenizers') == 0\n",
    "# Some colab bug requires matplotlib==3.1.3\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    assert x('pip install -U matplotlib==3.1.3') == 0\n",
    "if USE_DEEPSPEED:\n",
    "    assert x('pip install -U deepspeed') == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# clone repo if this is just the notebook file (current folder is not 'rq1'), then cd to the cloned repo\n",
    "if not os.path.abspath(os.getcwd()).endswith('rq1'):\n",
    "    # If llms-for-code-comment-consistency exists, then go in and pull any updates\n",
    "    if os.path.exists('llms-for-code-comment-consistency'):\n",
    "        os.chdir('llms-for-code-comment-consistency')\n",
    "        # Update if already exists\n",
    "        try:\n",
    "            assert x('git pull origin main --ff-only') == 0\n",
    "        except AssertionError:\n",
    "            # old version of git doesn't support --ff-only\n",
    "            assert x('git pull origin main') == 0\n",
    "    else:\n",
    "        assert x(f'git clone {REPO_URL}') == 0\n",
    "        os.chdir('llms-for-code-comment-consistency')\n",
    "else:\n",
    "    # cd to parent of this folder for the root of the repo\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "\n",
    "sys.path.append('lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:00:45.476009Z",
     "iopub.status.busy": "2022-12-10T22:00:45.475713Z",
     "iopub.status.idle": "2022-12-10T22:00:53.062797Z",
     "shell.execute_reply": "2022-12-10T22:00:53.061218Z",
     "shell.execute_reply.started": "2022-12-10T22:00:45.475979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU info:\n",
      "Architecture:                    aarch64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Byte Order:                      Little Endian\n",
      "CPU(s):                          4\n",
      "On-line CPU(s) list:             0-3\n",
      "Vendor ID:                       ARM\n",
      "Model name:                      Neoverse-N1\n",
      "Model:                           1\n",
      "Thread(s) per core:              1\n",
      "Core(s) per cluster:             4\n",
      "Socket(s):                       -\n",
      "Cluster(s):                      1\n",
      "Stepping:                        r3p1\n",
      "BogoMIPS:                        50.00\n",
      "Flags:                           fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm lrcpc dcpop asimddp ssbs\n",
      "NUMA node(s):                    1\n",
      "NUMA node0 CPU(s):               0-3\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Not affected\n",
      "Vulnerability Mds:               Not affected\n",
      "Vulnerability Meltdown:          Not affected\n",
      "Vulnerability Mmio stale data:   Not affected\n",
      "Vulnerability Retbleed:          Not affected\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl\n",
      "Vulnerability Spectre v1:        Mitigation; __user pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; CSV2, BHB\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Not affected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from time import time\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x('nvidia-smi')\n",
    "elif REQUIRE_CUDA:\n",
    "    raise RuntimeError(\"CUDA not available\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "\n",
    "# Print CPU info\n",
    "print(\"CPU info:\")\n",
    "x('lscpu')\n",
    "    \n",
    "# if we want to use deepspeed and only 1 gpu is available\n",
    "if USE_DEEPSPEED and torch.cuda.device_count() == 1:\n",
    "    os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "    os.environ[\"RANK\"] = \"0\"\n",
    "    os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "    os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "\n",
    "import wandb\n",
    "\n",
    "if USE_WANDB:\n",
    "    wandb.login(key=WANDB_KEY)\n",
    "    run = wandb.init(project=f\"{MODEL_TYPE}-model-master\")\n",
    "    if N_EPOCHS == 0:\n",
    "        run.name = RUN_NAME + \"_eval\"\n",
    "    else:\n",
    "        run.name = RUN_NAME\n",
    "    run.notes = RUN_NOTES\n",
    "else:\n",
    "    wandb.init(project=f\"{MODEL_TYPE}-model-master\", mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:00:53.065358Z",
     "iopub.status.busy": "2022-12-10T22:00:53.064603Z",
     "iopub.status.idle": "2022-12-10T22:01:12.311497Z",
     "shell.execute_reply": "2022-12-10T22:01:12.310226Z",
     "shell.execute_reply.started": "2022-12-10T22:00:53.065304Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-05 12:22:10,886] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Downloading CodeGen config files\n",
      "Creating model from config\n",
      "CodeGenBasedModel(\n",
      "  (codegen_tf): CodeGenModel(\n",
      "    (wte): Embedding(51200, 1024)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-19): 20 x CodeGenBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): CodeGenAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (qkv_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "        )\n",
      "        (mlp): CodeGenMLP(\n",
      "          (fc_in): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc_out): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=1024, out_features=2, bias=True)\n",
      "    (3): Softmax(dim=1)\n",
      "  )\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      "  (lm_head): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=1024, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model class\n",
    "from models import get_model\n",
    "\n",
    "my_model, tokenizer, config = get_model(MODEL_TYPE, MODEL_SIZE, freeze_base=FREEZE_BASE_MODEL)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:01:12.951360Z",
     "iopub.status.busy": "2022-12-10T22:01:12.950930Z",
     "iopub.status.idle": "2022-12-10T22:01:39.583505Z",
     "shell.execute_reply": "2022-12-10T22:01:39.582072Z",
     "shell.execute_reply.started": "2022-12-10T22:01:12.951360Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_from_file, get_collate_fn\n\u001b[0;32m----> 3\u001b[0m collate_fn \u001b[39m=\u001b[39m get_collate_fn(tokenizer)\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mensure_data_folder\u001b[39m(folder):\n\u001b[1;32m      6\u001b[0m     \u001b[39m# If the data folder does not exist, extract it from the .tar.gz file\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(folder):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "from data import dataset_from_file, get_collate_fn\n",
    "\n",
    "collate_fn = get_collate_fn(tokenizer)\n",
    "\n",
    "def ensure_data_folder(folder):\n",
    "    # If the data folder does not exist, extract it from the .tar.gz file\n",
    "    if not os.path.exists(folder):\n",
    "        print('Extracting data...')\n",
    "        if not os.path.exists(f'{folder}.tar.gz'):\n",
    "            print('Downloading data from server...')\n",
    "            assert x(f'wget -O {folder}.tar.gz https://file2.pelmers.com/{folder}.tar.gz') == 0\n",
    "        assert x(f'tar -xzf {folder}.tar.gz -C data') == 0\n",
    "\n",
    "ensure_data_folder(DATA_FOLDER)\n",
    "\n",
    "train_raw, train_dataset = dataset_from_file('{}/train.json'.format(DATA_FOLDER), MODEL_TYPE, tokenizer, MAX_LENGTH)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "if USE_EXTRAS_FILE:\n",
    "    extras_raw, extras_dataset = dataset_from_file('{}/extras.json'.format(DATA_FOLDER), MODEL_TYPE, tokenizer, MAX_LENGTH)\n",
    "    extras_dataloader = DataLoader(extras_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# TODO: use valid\n",
    "val_raw, val_dataset = dataset_from_file('{}/valid.json'.format(DATA_FOLDER), MODEL_TYPE, tokenizer, MAX_LENGTH)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "test_raw, test_dataset = dataset_from_file('{}/test.json'.format(DATA_FOLDER), MODEL_TYPE, tokenizer, MAX_LENGTH)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:01:39.588260Z",
     "iopub.status.busy": "2022-12-10T22:01:39.587955Z",
     "iopub.status.idle": "2022-12-10T22:01:39.778175Z",
     "shell.execute_reply": "2022-12-10T22:01:39.776261Z",
     "shell.execute_reply.started": "2022-12-10T22:01:39.588232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 125237762\n"
     ]
    }
   ],
   "source": [
    "# Model instantiation\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "x('mkdir -p checkpoints')\n",
    "\n",
    "use_cuda = torch.cuda.is_available() and not USE_DEEPSPEED\n",
    "\n",
    "if use_cuda:\n",
    "    my_model.cuda()\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        my_model = nn.DataParallel(my_model)\n",
    "\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr=LEARNING_RATE)\n",
    "start_epoch = 0\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    # Find the latest checkpoint\n",
    "    checkpoints = glob.glob('checkpoints/*.pt')\n",
    "    checkpoints.sort()\n",
    "    checkpoints = [ckpt for ckpt in checkpoints if ckpt_basename in ckpt if LOAD_MODEL_F1_OR_PREC in ckpt]\n",
    "    if len(checkpoints) > 0:\n",
    "        print('Loading model from {}'.format(checkpoints[-1]))\n",
    "        prev_state = torch.load(checkpoints[-1])\n",
    "        my_model.load_state_dict(prev_state['model_state_dict'])\n",
    "        optimizer.load_state_dict(prev_state['optimizer_state_dict'])\n",
    "        start_epoch = prev_state['epoch']\n",
    "        print('Loaded model from epoch {}, file {}'.format(start_epoch, checkpoints[-1]))\n",
    "    else:\n",
    "        print('No checkpoints found matching {}'.format(ckpt_basename))\n",
    "        raise FileNotFoundError\n",
    "\n",
    "# Print the number of parameters in the model\n",
    "total_params = sum(p.numel() for p in my_model.parameters())\n",
    "print('Total number of parameters: {}'.format(total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:01:39.787106Z",
     "iopub.status.busy": "2022-12-10T22:01:39.786565Z",
     "iopub.status.idle": "2022-12-10T22:01:40.042853Z",
     "shell.execute_reply": "2022-12-10T22:01:40.041922Z",
     "shell.execute_reply.started": "2022-12-10T22:01:39.787021Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define evaluation function\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "def compute_model_metrics(model, dataloader, language=RUN_LANGUAGE, positive_threshold=None):\n",
    "    '''\n",
    "    Return a dictionary representing the metrics for the model on the given dataset.\n",
    "    '''\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    truths = []\n",
    "    loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids, attention_mask, labels, _ = batch\n",
    "        if torch.cuda.is_available():\n",
    "            input_ids = input_ids.cuda()\n",
    "            attention_mask = attention_mask.cuda()\n",
    "            labels = labels.cuda()\n",
    "        with torch.no_grad():\n",
    "            prob, loss, _ = model(input_ids, attention_mask, labels)\n",
    "            loss += loss.item()\n",
    "            probs.append(prob.cpu().numpy())\n",
    "            truths.append(labels.cpu().numpy())\n",
    "    print()\n",
    "    probs = np.concatenate(probs)\n",
    "    truths = np.concatenate(truths)\n",
    "    loss /= len(dataloader)\n",
    "    sample_weights = np.ones(len(truths))\n",
    "    # make the sample_weights array the same size as the number of samples in the dataset, with 1 for positive and weight for negative\n",
    "    sample_weights[truths == 0] = NEGATIVE_TO_POSITIVE_RATIO\n",
    "    predictions_05 = (probs[:, 1] > 0.5).astype(int)\n",
    "    if not TUNE_THRESHOLD:\n",
    "        positive_threshold = 0.5\n",
    "    if positive_threshold is None:\n",
    "        best_weighted_f1 = -1\n",
    "        best_predictions = None\n",
    "        for t in np.arange(0, 1, 0.0005):\n",
    "            # t is the threshold for positive classification, so 1-t is the threshold for negative classification\n",
    "            predictions = (probs[:, 1] > t).astype(int)\n",
    "            weighted_f1 = sklearn.metrics.f1_score(truths, predictions, sample_weight=sample_weights)\n",
    "            if weighted_f1 > best_weighted_f1:\n",
    "                best_weighted_f1 = weighted_f1\n",
    "                best_predictions = predictions\n",
    "                positive_threshold = t\n",
    "    else:\n",
    "        best_predictions = (probs[:, 1] > positive_threshold).astype(int)\n",
    "        best_weighted_f1 = sklearn.metrics.f1_score(truths, best_predictions, sample_weight=sample_weights)\n",
    "    acc = sklearn.metrics.accuracy_score(truths, best_predictions)\n",
    "    acc_05 = sklearn.metrics.accuracy_score(truths, predictions_05)\n",
    "    f1 = sklearn.metrics.f1_score(truths, best_predictions)\n",
    "    f1_05 = sklearn.metrics.f1_score(truths, predictions_05)\n",
    "    precision = sklearn.metrics.precision_score(truths, best_predictions)\n",
    "    recall = sklearn.metrics.recall_score(truths, best_predictions)\n",
    "    confusion = sklearn.metrics.confusion_matrix(truths, best_predictions)\n",
    "    metrics = {\n",
    "        'acc': acc,\n",
    "        'acc_05': acc_05,\n",
    "        'f1': f1,\n",
    "        'f1_05': f1_05,\n",
    "        'weighted_f1': best_weighted_f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'loss': loss,\n",
    "        'confusion': confusion,\n",
    "        'probs': probs,\n",
    "        'labels': truths,\n",
    "        'predictions': best_predictions,\n",
    "        'positive_threshold': positive_threshold\n",
    "    }\n",
    "    if DEBUG:\n",
    "        from pprint import pprint\n",
    "        print('Metrics:')\n",
    "        pprint(metrics)\n",
    "    return metrics\n",
    "\n",
    "METRICS_KEYS = ['acc', 'acc_05', 'f1', 'f1_05', 'precision', 'recall', 'loss', 'weighted_f1', 'positive_threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:01:40.047115Z",
     "iopub.status.busy": "2022-12-10T22:01:40.046786Z",
     "iopub.status.idle": "2022-12-10T22:02:09.954448Z",
     "shell.execute_reply": "2022-12-10T22:02:09.952875Z",
     "shell.execute_reply.started": "2022-12-10T22:01:40.047088Z"
    }
   },
   "outputs": [],
   "source": [
    "DEEPSPEED_CONFIG = \\\n",
    "{\n",
    "    'fp16': {'enabled': True, 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 12, 'hysteresis': 2, 'min_loss_scale': 1},\n",
    "    'optimizer': {'type': 'AdamW', 'params': {'lr': LEARNING_RATE, 'betas': [0.9, 0.99], 'eps': 1e-08, 'weight_decay': 1e-7}},\n",
    "    'scheduler': {'type': 'WarmupLR', 'params': {'warmup_min_lr': 0, 'warmup_max_lr': LEARNING_RATE, 'warmup_num_steps': 10}},\n",
    "    'zero_optimization': {\n",
    "        'stage': 3,\n",
    "        'offload_optimizer': {'device': 'cpu', 'pin_memory': True},\n",
    "        'offload_param': {'device': 'cpu', 'pin_memory': True},\n",
    "        'overlap_comm': True,\n",
    "        'contiguous_gradients': True,\n",
    "    },\n",
    "    'allgather_partitions': True,\n",
    "    'overlap_comm': True,\n",
    "    'contiguous_gradients': True,\n",
    "    'train_batch_size': BATCH_SIZE,\n",
    "    'gradient_accumulation_steps': BATCH_SIZE,\n",
    "    'steps_per_print': float('inf'),\n",
    "    'wall_clock_breakdown': False,\n",
    "}\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "if USE_DEEPSPEED:\n",
    "    import deepspeed\n",
    "    deepspeed.runtime.utils.see_memory_usage('before model load', force=True)\n",
    "    my_model_parameters = list(filter(lambda p: p.requires_grad, my_model.parameters()))\n",
    "    model_engine, optimizer, _, _ = deepspeed.initialize(config=DEEPSPEED_CONFIG, model=my_model, model_parameters=my_model_parameters)\n",
    "    torch.cuda.empty_cache() \n",
    "    deepspeed.runtime.utils.see_memory_usage('model loaded', force=True)\n",
    "    # Turn off annoying print in timer\n",
    "    old_stop_func = model_engine.tput_timer.stop\n",
    "    def new_stop(*args, **kwargs):\n",
    "        kwargs['report_speed'] = False\n",
    "        old_stop_func(*args, **kwargs)\n",
    "    model_engine.tput_timer.stop = new_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-10T22:02:09.959953Z",
     "iopub.status.busy": "2022-12-10T22:02:09.959503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1\n",
      "Concatenated dataset with 237179 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 34/34 [00:35<00:00,  1.04s/it, [Loss: 0.396441787481308]]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.5209985226392746, accuracy: 0.9901960790157318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 357/734 [04:51<05:07,  1.23it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining loss: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39msum\u001b[39m(epoch_loss) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(epoch_loss)\u001b[39m}\u001b[39;00m\u001b[39m, accuracy: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39msum\u001b[39m(epoch_acc) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(epoch_acc)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[39m# Validate the model\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m metrics \u001b[39m=\u001b[39m compute_model_metrics(my_model, val_dataloader)\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m USE_WANDB:\n\u001b[1;32m     70\u001b[0m     wandb\u001b[39m.\u001b[39mlog({\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m k: metrics[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m METRICS_KEYS})\n",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m, in \u001b[0;36mcompute_model_metrics\u001b[0;34m(model, dataloader, language, positive_threshold)\u001b[0m\n\u001b[1;32m     18\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     19\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 20\u001b[0m     prob, loss, _ \u001b[39m=\u001b[39m model(input_ids, attention_mask, labels)\n\u001b[1;32m     21\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     22\u001b[0m     probs\u001b[39m.\u001b[39mappend(prob\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/thesis/master-project/notebooks/lib/models.py:56\u001b[0m, in \u001b[0;36mget_model.<locals>.CodeBERTBasedModel.forward\u001b[0;34m(self, input_ids, attention_mask, labels, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 56\u001b[0m     encoder_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(input_ids, attention_mask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     57\u001b[0m     cls_encoded \u001b[39m=\u001b[39m encoder_out[\u001b[39m0\u001b[39m][:, \u001b[39m0\u001b[39m, :]  \u001b[39m# take <s> token (equiv. to [CLS])\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(cls_encoded)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:852\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    843\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    845\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    846\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    847\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    850\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    851\u001b[0m )\n\u001b[0;32m--> 852\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    853\u001b[0m     embedding_output,\n\u001b[1;32m    854\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    855\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    856\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    857\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    858\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    859\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    860\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    861\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    862\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    863\u001b[0m )\n\u001b[1;32m    864\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    865\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:527\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    518\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    520\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    528\u001b[0m         hidden_states,\n\u001b[1;32m    529\u001b[0m         attention_mask,\n\u001b[1;32m    530\u001b[0m         layer_head_mask,\n\u001b[1;32m    531\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    532\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    533\u001b[0m         past_key_value,\n\u001b[1;32m    534\u001b[0m         output_attentions,\n\u001b[1;32m    535\u001b[0m     )\n\u001b[1;32m    537\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:453\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    450\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    451\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 453\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    454\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    455\u001b[0m )\n\u001b[1;32m    456\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    458\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 237\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:465\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> 465\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    466\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    467\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:363\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 363\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    364\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    365\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "import random\n",
    "\n",
    "best_val_f1 = -1\n",
    "best_val_positive_threshold = -1\n",
    "best_val_prec = -1\n",
    "\n",
    "ckpt_basename = f'ckpt_{RUN_NAME}'\n",
    "if N_EPOCHS == 0:\n",
    "    metrics = compute_model_metrics(my_model, val_dataloader)\n",
    "    best_val_f1 = metrics['weighted_f1']\n",
    "    best_val_positive_threshold = metrics['positive_threshold']\n",
    "    best_val_prec = metrics['precision']\n",
    "\n",
    "for epoch in range(start_epoch, N_EPOCHS):\n",
    "    print('Epoch {} / {}'.format(epoch + 1, N_EPOCHS))\n",
    "    my_model.train()\n",
    "    if USE_EXTRAS_FILE:\n",
    "        from data import CustomConcatDataset, custom_dataset_from_zipped_items\n",
    "        # Create new dataset with balanced sample from train + extras\n",
    "        n_examples_in_epoch = len(train_dataset)\n",
    "        concat_ds = CustomConcatDataset(train_dataset, extras_dataset)\n",
    "        negative_items = [i for i in concat_ds if i[1] == 0]\n",
    "        positive_items = [i for i in concat_ds if i[1] == 1]\n",
    "        random.shuffle(negative_items)\n",
    "        random.shuffle(positive_items)\n",
    "        concat_ds = custom_dataset_from_zipped_items(negative_items[:n_examples_in_epoch//2] + positive_items[:n_examples_in_epoch//2])\n",
    "        train_dataloader = DataLoader(concat_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    if DEBUG:\n",
    "        # In debug mode just load a random sample of 100 from the training set\n",
    "        ds = train_dataset if not USE_EXTRAS_FILE else concat_ds\n",
    "        train_dataloader = DataLoader(ds, batch_size=BATCH_SIZE, collate_fn=collate_fn, sampler=torch.utils.data.SubsetRandomSampler(range(100)))\n",
    "    # Log loss at least 100 times per epoch\n",
    "    loss_log_interval = max(1, len(train_dataloader) // 100)\n",
    "    bar = tqdm(train_dataloader, bar_format='{l_bar}{bar:16}{r_bar}')\n",
    "    # Record loss values to average out for logging\n",
    "    loss_accum = []\n",
    "    acc_accum = []\n",
    "    epoch_acc = []\n",
    "    epoch_loss = []\n",
    "    for step, batch in enumerate(bar):\n",
    "        input_ids, attention_mask, labels, _ = batch\n",
    "        if use_cuda or USE_DEEPSPEED:\n",
    "            input_ids = input_ids.cuda()\n",
    "            attention_mask = attention_mask.cuda()\n",
    "            labels = labels.cuda()\n",
    "        if USE_DEEPSPEED:\n",
    "            prob, loss, _ = model_engine(input_ids, attention_mask, labels)\n",
    "            model_engine.backward(loss)\n",
    "            model_engine.step()\n",
    "        else:\n",
    "            prob, loss, _ = my_model(input_ids, attention_mask, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        loss_accum.append(loss.item())\n",
    "        acc_accum.append((prob.argmax(dim=1) == labels).float().mean().item())\n",
    "        if step % loss_log_interval == 0:\n",
    "            loss_avg = sum(loss_accum) / len(loss_accum) if len(loss_accum) > 0 else 0\n",
    "            acc_avg = sum(acc_accum) / len(acc_accum) if len(acc_accum) > 0 else 0\n",
    "            bar.set_postfix_str('[Loss: {}]'.format(loss_avg))\n",
    "            epoch_acc.append(acc_avg)\n",
    "            epoch_loss.append(loss_avg)\n",
    "            loss_accum = []\n",
    "            acc_accum = []\n",
    "            if USE_WANDB:\n",
    "                wandb.log({'train_loss': loss_avg, 'train_acc': acc_avg})\n",
    "\n",
    "    print()\n",
    "    print(f'Training loss: {sum(epoch_loss) / len(epoch_loss)}, accuracy: {sum(epoch_acc) / len(epoch_acc)}')\n",
    "    # Validate the model\n",
    "    metrics = compute_model_metrics(my_model, val_dataloader)\n",
    "    if USE_WANDB:\n",
    "        wandb.log({'val_' + k: metrics[k] for k in METRICS_KEYS})\n",
    "    print(f'Validation loss: {metrics[\"loss\"]}, accuracy: {metrics[\"acc\"]}, F1: {metrics[\"f1\"]}, precision: {metrics[\"precision\"]}, weighted f1: {metrics[\"weighted_f1\"]} at threshold {metrics[\"positive_threshold\"]}')\n",
    "\n",
    "    def save(filename):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': my_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'model_type': MODEL_TYPE,\n",
    "            'model_size': MODEL_SIZE,\n",
    "            'max_length': MAX_LENGTH,\n",
    "            'loss': loss,\n",
    "            'positive_threshold': metrics['positive_threshold'],\n",
    "        }, filename)\n",
    "\n",
    "    # Save a checkpoint of the model and optimizer state\n",
    "    if SAVE_CHECKPOINTS:\n",
    "        if (epoch + 1) % SAVE_CHECKPOINT_INTERVAL == 0 or (epoch + 1) == N_EPOCHS:\n",
    "            ckpt_file = 'checkpoints/{}_{}.pt'.format(ckpt_basename, epoch)\n",
    "            save(ckpt_file)\n",
    "            print('Saved checkpoint to {}'.format(ckpt_file))\n",
    "    if metrics['weighted_f1'] >= best_val_f1:\n",
    "        if SAVE_BEST:\n",
    "            ckpt_file = f'checkpoints/{ckpt_basename}_best_f1.pt'\n",
    "            save(ckpt_file)\n",
    "            print('Saved checkpoint to {}'.format(ckpt_file))\n",
    "        best_val_f1 = metrics['weighted_f1']\n",
    "        best_val_positive_threshold = metrics['positive_threshold']\n",
    "    if metrics['precision'] >= best_val_prec:\n",
    "        if SAVE_BEST:\n",
    "            ckpt_file = f'checkpoints/{ckpt_basename}_best_prec.pt'\n",
    "            save(ckpt_file)\n",
    "            print('Saved checkpoint to {}'.format(ckpt_file))\n",
    "        best_val_prec = metrics['precision']\n",
    "\n",
    "\n",
    "# Save best model to wandb\n",
    "if USE_WANDB and SAVE_BEST and SAVE_ARTIFACTS_WANDB:\n",
    "    wandb.save(f'checkpoints/{ckpt_basename}_best_f1.pt', policy='end')\n",
    "    wandb.save(f'checkpoints/{ckpt_basename}_best_prec.pt', policy='end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 734/734 [09:35<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of validation set\n",
      "[[   0 1100]\n",
      " [   0 1100]]\n",
      "false positives: 1100, false negatives: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model with best validation score\n",
    "if SAVE_BEST:\n",
    "    ckpt_file = f'checkpoints/{ckpt_basename}_best_f1.pt'\n",
    "    print('Loading best validation model from {}'.format(ckpt_file))\n",
    "    prev_state = torch.load(ckpt_file)\n",
    "    my_model.load_state_dict(prev_state['model_state_dict'])\n",
    "    print('Loaded model from epoch {}, file {}'.format(prev_state['epoch'], ckpt_file))\n",
    "\n",
    "# Sample examples of mispredicted items from the validation set\n",
    "# list of data item, correct label, predicted label\n",
    "val_mispredictions = []\n",
    "val_goodpredictions = []\n",
    "val_predicted_vs_labeled = []\n",
    "\n",
    "for val_batch in tqdm(val_dataloader):\n",
    "    input_ids, attention_mask, labels, original_index = val_batch\n",
    "    if torch.cuda.is_available():\n",
    "        input_ids = input_ids.cuda()\n",
    "        attention_mask = attention_mask.cuda()\n",
    "        labels = labels.cuda()\n",
    "    with torch.no_grad():\n",
    "        prob, loss, _ = my_model(input_ids, attention_mask, labels)\n",
    "        pred = torch.argmax(prob, dim=1)\n",
    "        for i in range(len(pred)):\n",
    "            raw_entry = val_raw[original_index[i]]\n",
    "            if pred[i] != labels[i]:\n",
    "                val_mispredictions.append((raw_entry, original_index[i], labels[i], pred[i]))\n",
    "            else:\n",
    "                val_goodpredictions.append((raw_entry, original_index[i], labels[i], pred[i]))\n",
    "            val_predicted_vs_labeled.append((pred[i].item(), labels[i].item()))\n",
    "\n",
    "cm = metrics['confusion']\n",
    "print('Confusion matrix of validation set')\n",
    "print(cm)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"false positives: {fp}, false negatives: {fn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mispredicted examples:\n",
      "Example mdnsk/leo-translate.git#8\n",
      "Correct label: 0\n",
      "Predicted label: 1\n",
      "// Return all options\n",
      "getAllOptions () {\n",
      "  return new Promise(resolve => {\n",
      "    chrome.storage.local.get({ options: {}}, data => {\n",
      "      const options = {};\n",
      "\n",
      "      for (const key in defaultValues) {\n",
      "          if (defaultValues.hasOwnProperty(key)) {\n",
      "              options[key] = getOptionValue(typeof data === 'object' ? data.options : {}, key);\n",
      "          }\n",
      "      }\n",
      "\n",
      "      return resolve(options);\n",
      "    })\n",
      "  });\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Example iTwin/itwinjs-core.git#601\n",
      "Correct label: 0\n",
      "Predicted label: 1\n",
      "// Return true if the geometry is or would be represented by a wire body.\n",
      "public isWire(): boolean {\n",
      "  switch (this._type) {\n",
      "    case GeometryType.CurvePrimitive:\n",
      "      return true;\n",
      "    //  return !(this._data instanceof PointString);\n",
      "    case GeometryType.CurveCollection:\n",
      "      return this.asCurveCollection!.isOpenPath();\n",
      "    // case GeometryType.BRepEntity:\n",
      "    //  return ...\n",
      "    default:\n",
      "      return false;\n",
      "  }\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Example sebastianhaas/medical-appointment-scheduling.git#44\n",
      "Correct label: 0\n",
      "Predicted label: 1\n",
      "// Create a change stream.\n",
      "public auditLogEntryCreateChangeStreamGetAuditLogEntriesChangeStream (options?: string, extraHttpRequestParams?: any ) : Observable<any> {\n",
      "    const path = this.basePath + '/AuditLogEntries/change-stream';\n",
      "\n",
      "    let queryParameters = new URLSearchParams();\n",
      "    let headerParams = this.defaultHeaders;\n",
      "    if (options !== undefined) {\n",
      "        queryParameters.set('options', String(options));\n",
      "    }\n",
      "\n",
      "    let requestOptions: RequestOptionsArgs = {\n",
      "        method: 'GET',\n",
      "        headers: headerParams,\n",
      "        search: queryParameters\n",
      "    };\n",
      "\n",
      "    return this.http.request(path, requestOptions)\n",
      "        .map((response: Response) => {\n",
      "            if (response.status === 204) {\n",
      "                return undefined;\n",
      "            } else {\n",
      "                return response.json();\n",
      "            }\n",
      "        });\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Example jakezatecky/react-dual-listbox.git#44\n",
      "Correct label: 0\n",
      "Predicted label: 1\n",
      "// Filter the selected options.\n",
      "filterSelected(options) {\n",
      "    const { preserveSelectOrder, selected } = this.props;\n",
      "    const { filter: { selected: selectedFilter } } = this.state;\n",
      "\n",
      "    if (preserveSelectOrder) {\n",
      "        return this.filterSelectedByOrder(options);\n",
      "    }\n",
      "\n",
      "    // Order the selections by the default order\n",
      "    return this.filterOptions(\n",
      "        options,\n",
      "        (option) => indexesOf(this.getFlatOptions(selected), option.value),\n",
      "        selectedFilter,\n",
      "    );\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Example kontent-ai/delivery-sdk-js.git#302\n",
      "Correct label: 0\n",
      "Predicted label: 1\n",
      "// Gets single content type element from given url\n",
      "getElement(\n",
      "  url: string,\n",
      "  queryConfig: ITaxonomyQueryConfig\n",
      "): Observable<ElementResponses.ElementResponse> {\n",
      "  return this.getResponse(url, queryConfig).pipe(\n",
      "    map(response => {\n",
      "      return this.responseMapper.mapElementResponse(response);\n",
      "    })\n",
      "  );\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Example TheFutureGadgetsLab/WaifuXL.git#9\n",
      "Correct label: 0\n",
      "Predicted label: 1\n",
      "// Given some input, return the data URI from that.\n",
      "function getDataURIFromInput(input) {\n",
      "  return new Promise(async (resolve, reject) => {\n",
      "    if (isValidHttpUrl(input)) {\n",
      "      const blob = await fetch(input).then((r) => r.blob())\n",
      "      const dataUrl = await new Promise((resolve) => {\n",
      "        const reader = new FileReader()\n",
      "        reader.onload = () => resolve(reader.result)\n",
      "        reader.readAsDataURL(blob)\n",
      "      })\n",
      "      resolve(dataUrl)\n",
      "    } else {\n",
      "      const img = new Image()\n",
      "      img.src = input\n",
      "      img.crossOrigin = 'Anonymous'\n",
      "      img.onload = function () {\n",
      "        const canvas = document.createElement('canvas')\n",
      "        canvas.width = img.width\n",
      "        canvas.height = img.height\n",
      "        const context = canvas.getContext('2d')\n",
      "        context.drawImage(img, 0, 0)\n",
      "        resolve(canvas.toDataURL())\n",
      "      }\n",
      "    }\n",
      "  })\n",
      "}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# First shuffle the prediction lists\n",
    "\n",
    "random.shuffle(val_mispredictions)\n",
    "\n",
    "n_to_check = 6\n",
    "\n",
    "print('Mispredicted examples:')\n",
    "for raw_entry, input_id, label, pred in val_mispredictions[:n_to_check]:\n",
    "    # combine new comment with new code in raw entry to get full text\n",
    "    text = raw_entry['old_comment_raw'] + '\\n' + raw_entry['new_code_raw']\n",
    "    if 'id' in raw_entry:\n",
    "        example_id = raw_entry['id']\n",
    "    else:\n",
    "        example_id = input_id\n",
    "    print('Example {}'.format(example_id))\n",
    "    print('Correct label: {}'.format(label))\n",
    "    print('Predicted label: {}'.format(pred))\n",
    "    print('// {}'.format(text))\n",
    "    if label == 1:\n",
    "        print('--- correct (new) comment ---')\n",
    "        print('// {}'.format(raw_entry['new_comment_raw']))\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly predicted examples:\n",
      "Example WFCD/warframe-worldstate-parser.git#5\n",
      "Correct label: 1\n",
      "Predicted label: 1\n",
      "// The alert's reward types\n",
      "getRewardTypes() {\n",
      "  return this.reward.getTypes();\n",
      "}\n",
      "--- correct (new) comment ---\n",
      "// Get an array containing the types of all of the alert's rewards\n",
      "--------------------------------------------------------------------------------\n",
      "Example GetScatter/ScatterWebExtension.git#65\n",
      "Correct label: 1\n",
      "Predicted label: 1\n",
      "// Created a hash of the entire message\n",
      "static messageChecksum(message, signingAccountName, domain, network, requiredFields = []){\n",
      "    return Hasher.insecureHash(JSON.stringify(Object.assign(message, {domain, network, requiredFields})))\n",
      "}\n",
      "--- correct (new) comment ---\n",
      "// Created a insecureHash of the entire message\n",
      "--------------------------------------------------------------------------------\n",
      "Example dockstore/dockstore-ui2.git#628\n",
      "Correct label: 1\n",
      "Predicted label: 1\n",
      "// Filters the organization based on a string Case insensitive Partial match\n",
      "filterOrganizations(organizations: Array<Organization>, searchName: string): Array<Organization> | null {\n",
      "  searchName = searchName.toLowerCase();\n",
      "  if (organizations) {\n",
      "    return searchName\n",
      "      ? organizations.filter(organization => {\n",
      "          const matchOptions: string[] = [\n",
      "            organization.description,\n",
      "            organization.displayName,\n",
      "            organization.location,\n",
      "            organization.name,\n",
      "            organization.topic\n",
      "          ].filter(matchOption => !!matchOption);\n",
      "          return matchOptions.some(stringIdentifier => stringIdentifier.toLowerCase().includes(searchName));\n",
      "        })\n",
      "      : organizations;\n",
      "  }\n",
      "  return null;\n",
      "}\n",
      "--- correct (new) comment ---\n",
      "// Filters the organization based on a string Case insensitive Partial match Searches the name, description, displayName, location, and topic of each organization (does not search its collections)\n",
      "--------------------------------------------------------------------------------\n",
      "Example nesk/network.js.git#0\n",
      "Correct label: 1\n",
      "Predicted label: 1\n",
      "// Only for testing purposes! Exposes all the internal classes to the global scope.\n",
      "static _exposeInternalClasses()\n",
      "{\n",
      "    var classes = {EventDispatcher, HttpModule, LatencyModule, BandwidthModule, Timing};\n",
      "\n",
      "    Object.keys(classes).forEach(name => {\n",
      "        window[name] = classes[name];\n",
      "    });\n",
      "\n",
      "    return this;\n",
      "}\n",
      "--- correct (new) comment ---\n",
      "// Expose all the internal classes to the global scope.\n",
      "--------------------------------------------------------------------------------\n",
      "Example fantasycalendar/FoundryVTT-Sequencer.git#331\n",
      "Correct label: 1\n",
      "Predicted label: 1\n",
      "// Gets all files under a module\n",
      "getAllFileEntries(inDBPath) {\n",
      "    if (typeof inDBPath !== \"string\") return this._throwError(\"getAllFileEntries\", \"inString must be of type string\");\n",
      "    if (!this.entryExists(inDBPath)) return this._throwError(\"getAllFileEntries\", `Could not find ${inDBPath} in database`);\n",
      "    const entries = this._recurseEntriesUnder(inDBPath);\n",
      "    return lib.makeArrayUnique(entries.flat());\n",
      "}\n",
      "--- correct (new) comment ---\n",
      "// Gets all files under a database path\n",
      "--------------------------------------------------------------------------------\n",
      "Example iTwin/itwinjs-core.git#2085\n",
      "Correct label: 1\n",
      "Predicted label: 1\n",
      "// Get the value of the specified column in the ECSQL query result as XAndY.\n",
      "public getXYAndZ(): XYAndZ { return this._val.getPoint3d(); }\n",
      "--- correct (new) comment ---\n",
      "// Get the value as [[XYAndZ]]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(val_goodpredictions)\n",
    "\n",
    "print('Correctly predicted examples:')\n",
    "for raw_entry, input_id, label, pred in val_goodpredictions[:n_to_check]:\n",
    "    # combine new comment with new code in raw entry to get full text\n",
    "    text = raw_entry['old_comment_raw'] + '\\n' + raw_entry['new_code_raw']\n",
    "    if 'id' in raw_entry:\n",
    "        example_id = raw_entry['id']\n",
    "    else:\n",
    "        example_id = input_id\n",
    "    print('Example {}'.format(example_id))\n",
    "    print('Correct label: {}'.format(label))\n",
    "    print('Predicted label: {}'.format(pred))\n",
    "    print('// {}'.format(text))\n",
    "    if label == 1:\n",
    "        print('--- correct (new) comment ---')\n",
    "        print('// {}'.format(raw_entry['new_comment_raw']))\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 734/734 [09:38<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics:\n",
      "{'acc': 0.5,\n",
      " 'confusion': array([[   0, 1100],\n",
      "       [   0, 1100]]),\n",
      " 'f1': 0.6666666666666666,\n",
      " 'labels': array([1, 1, 1, ..., 0, 0, 0]),\n",
      " 'loss': tensor(0.0028),\n",
      " 'positive_threshold': 0.0,\n",
      " 'precision': 0.5,\n",
      " 'predictions': array([1, 1, 1, ..., 1, 1, 1]),\n",
      " 'probs': array([[0.21101841, 0.78898156],\n",
      "       [0.22203115, 0.7779689 ],\n",
      "       [0.2901392 , 0.7098608 ],\n",
      "       ...,\n",
      "       [0.22821952, 0.7717805 ],\n",
      "       [0.2569489 , 0.7430511 ],\n",
      "       [0.2140561 , 0.7859439 ]], dtype=float32),\n",
      " 'recall': 1.0,\n",
      " 'weighted_f1': 0.07342143906020394}\n",
      "Test loss: 0.0027777324430644512, accuracy: 0.5, F1: 0.6666666666666666, precision: 0.5, weighted f1: 0.07342143906020394\n",
      "Confusion matrix of test set\n",
      "[[   0 1100]\n",
      " [   0 1100]]\n",
      "false positives: 1100, false negatives: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_1653326/2628661953.py:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predictions = (probs[:, 1] > positive_threshold).astype(np.int) + (probs[:, 0] >= 1-positive_threshold).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating on test set')\n",
    "metrics = compute_model_metrics(my_model, test_dataloader, positive_threshold=best_val_positive_threshold)\n",
    "if USE_WANDB:\n",
    "    wandb.log({'test_' + k: metrics[k] for k in METRICS_KEYS})\n",
    "print(f'Test loss: {metrics[\"loss\"]}, accuracy: {metrics[\"acc\"]}, F1: {metrics[\"f1\"]}, precision: {metrics[\"precision\"]}, weighted f1: {metrics[\"weighted_f1\"]}')\n",
    "\n",
    "cm = metrics['confusion']\n",
    "print('Confusion matrix of test set')\n",
    "print(cm)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"false positives: {fp}, false negatives: {fn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a precision recall curve on the test set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# predict probabilities\n",
    "yhat = metrics['probs'][:, 1]\n",
    "threshold_range = np.arange(0.0, 1.0, 0.01)\n",
    "accuracies = []\n",
    "f1s = []\n",
    "best_acc = 0\n",
    "best_thresh = 0\n",
    "for threshold in threshold_range:\n",
    "    yhat_thresh = (yhat > threshold).astype(int)\n",
    "    accuracies.append(np.mean(yhat_thresh == metrics['labels']))\n",
    "    f1s.append(sklearn.metrics.f1_score(metrics['labels'], yhat_thresh))\n",
    "# Plot\n",
    "plt.plot(threshold_range, accuracies, marker='.')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Threshold')\n",
    "table = wandb.Table(data=list(zip(threshold_range, accuracies)), columns=[\"threshold\", \"accuracy\"])\n",
    "wandb.log({'accuracy_vs_threshold': wandb.plot.line(table, \"threshold\", \"accuracy\", title=\"Accuracy vs. Threshold\")})\n",
    "tablef1 = wandb.Table(data=list(zip(threshold_range, f1s)), columns=[\"threshold\", \"f1\"])\n",
    "wandb.log({'f1_vs_threshold': wandb.plot.line(table, \"threshold\", \"f1\", title=\"Unweighted F1 vs. Threshold\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.0\n",
      "Best accuracy: 0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print best threshold\n",
    "best_thresh = threshold_range[np.argmax(accuracies)]\n",
    "print(f\"Best threshold: {best_thresh}\")\n",
    "print(f\"Best accuracy: {np.max(accuracies)}\")\n",
    "\n",
    "# Then plot the precision recall curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(metrics['labels'], yhat)\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision vs. Recall')\n",
    "table = wandb.Table(data=list(zip(recall, precision)), columns=[\"recall\", \"precision\"])\n",
    "wandb.log({'precision_vs_recall': wandb.plot.line(table, \"recall\", \"precision\", title=\"Precision vs. Recall\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on additional test sets\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating on additional test sets')\n",
    "for path in ADDITIONAL_TEST_FILES:\n",
    "    folder = os.path.dirname(path)\n",
    "    ensure_data_folder(folder)\n",
    "    test_language = 'py' if 'python' in path.lower() else 'go' if 'go' in path.lower() else 'js' if 'js' in path.lower() else 'java'\n",
    "    print(f'Loaded test set for {test_language} from {path}')\n",
    "    new_data_raw, new_dataset = dataset_from_file(path, MODEL_TYPE, tokenizer, MAX_LENGTH)\n",
    "    new_dataloader = DataLoader(new_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "    metrics = compute_model_metrics(my_model, new_dataloader, language=test_language, positive_threshold=best_val_positive_threshold)\n",
    "    print(f'Results on {path}:')\n",
    "    print(f'Test loss: {metrics[\"loss\"]}, accuracy: {metrics[\"acc\"]}, F1: {metrics[\"f1\"]}, precision: {metrics[\"precision\"]}, weighted f1: {metrics[\"weighted_f1\"]} at threshold {metrics[\"positive_threshold\"]}')\n",
    "    if USE_WANDB:\n",
    "        log_prefix = path.replace('.json', '').replace('data/', '')\n",
    "        wandb.log({log_prefix + '_' + k: metrics[k] for k in METRICS_KEYS})\n",
    "    cm = metrics['confusion']\n",
    "    print('Confusion matrix of test set')\n",
    "    print(cm)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"false positives: {fp}, false negatives: {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2200 examples from data/JS-22k/valid.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:01<00:00, 1131.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 281600\n",
      "Total number of truncated examples: 1282\n",
      "Total number of input tokens (ignoring truncation): 227131\n",
      "Mean: 103.24136363636363\n",
      "Median: 128.0\n",
      "Standard deviation: 34.90503243157907\n",
      "Minimum: 20\n",
      "Maximum: 128\n",
      "Loading 2200 examples from data/JS-22k/valid.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:02<00:00, 1011.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 281600\n",
      "Total number of truncated examples: 1257\n",
      "Total number of input tokens (ignoring truncation): 226489\n",
      "Mean: 102.94954545454546\n",
      "Median: 128.0\n",
      "Standard deviation: 34.61118710071443\n",
      "Minimum: 17\n",
      "Maximum: 128\n",
      "Loading 2200 examples from data/JS-22k/valid.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:01<00:00, 1123.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 281600\n",
      "Total number of truncated examples: 1282\n",
      "Total number of input tokens (ignoring truncation): 227131\n",
      "Mean: 103.24136363636363\n",
      "Median: 128.0\n",
      "Standard deviation: 34.90503243157907\n",
      "Minimum: 20\n",
      "Maximum: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 734/734 [20:23<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Perform post-hoc evaluation, train threshold on validation set and then evaluate on test set\n",
    "# works by getting score for old comment + old code, and then old comment + new code\n",
    "# decide whether old comment is positive now by comparing scores with threshold\n",
    "\n",
    "from data import CustomPostHocDataset, get_posthoc_collate_fn\n",
    "\n",
    "posthoc_collate_fn = get_posthoc_collate_fn(tokenizer)\n",
    "\n",
    "# First create the validation CustomPostHocDataset\n",
    "# TODO: use valid\n",
    "val_posthoc_dataset = CustomPostHocDataset('{}/test.json'.format(DATA_FOLDER), MODEL_TYPE, tokenizer, MAX_LENGTH)\n",
    "val_posthoc_dataloader = DataLoader(val_posthoc_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=posthoc_collate_fn)\n",
    "\n",
    "def evaluate_posthoc(dataloader):\n",
    "    my_model.eval()\n",
    "    # Store the positive label scores as a list of tuples (old_score, new_score, label)\n",
    "    all_posthoc_scores = []\n",
    "    # Ask the model for predictions on the old and new cases of the validation set\n",
    "    for batch in tqdm(dataloader):\n",
    "        old_input_ids, old_attention_mask, new_input_ids, new_attention_mask, labels, _ = batch\n",
    "        if torch.cuda.is_available():\n",
    "            old_input_ids = old_input_ids.cuda()\n",
    "            old_attention_mask = old_attention_mask.cuda()\n",
    "            new_input_ids = new_input_ids.cuda()\n",
    "            new_attention_mask = new_attention_mask.cuda()\n",
    "            labels = labels.cuda()\n",
    "        with torch.no_grad():\n",
    "            old_probs = my_model(old_input_ids, old_attention_mask, labels)[0]\n",
    "            new_probs = my_model(new_input_ids, new_attention_mask, labels)[0]\n",
    "        for old, new, label in zip(old_probs, new_probs, labels):\n",
    "            # Store the scores for the positive label\n",
    "            all_posthoc_scores.append((old[1].item(), new[1].item(), label.item()))\n",
    "    return all_posthoc_scores\n",
    "\n",
    "val_posthoc_scores = evaluate_posthoc(val_posthoc_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cutoff: 0.008000000000000895\n",
      "Best accuracy: 0.5504545454545454\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the cutoff that maximizes accuracy: i.e. we predict 1 if new - old > cutoff and 0 otherwise\n",
    "\n",
    "# Sort by the score difference\n",
    "score_differences = sorted([(new - old, label) for old, new, label in val_posthoc_scores], key=lambda x: x[0], reverse=True)\n",
    "# Find the cutoff that maximizes accuracy\n",
    "accs = []\n",
    "cutoffs = np.arange(-1, 1, 0.001)\n",
    "for cutoff in cutoffs:\n",
    "    yhat = np.array([1 if diff > cutoff else 0 for diff, _ in score_differences])\n",
    "    acc = np.mean(yhat == np.array([label for _, label in score_differences]))\n",
    "    accs.append(acc)\n",
    "\n",
    "# Create plot\n",
    "plt.plot(cutoffs, accs, marker='.')\n",
    "plt.xlabel('Cutoff')\n",
    "plt.ylabel('Accuracy')\n",
    "table = wandb.Table(data=list(zip(cutoffs, accs)), columns=[\"cutoff\", \"accuracy\"])\n",
    "wandb.log({'accuracy_vs_cutoff': wandb.plot.line(table, \"cutoff\", \"accuracy\", title=\"Accuracy vs. Cutoff\")})\n",
    "\n",
    "# print best threshold\n",
    "best_cutoff = cutoffs[np.argmax(accs)]\n",
    "print(f\"Best cutoff: {best_cutoff}\")\n",
    "print(f\"Best accuracy: {np.max(accs)}\")\n",
    "# Log to wandb\n",
    "if USE_WANDB:\n",
    "    wandb.log({'posthoc_best_cutoff': best_cutoff, 'posthoc_best_acc': np.max(accs)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2200 examples from data/JS-22k/test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:01<00:00, 1102.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 281600\n",
      "Total number of truncated examples: 1333\n",
      "Total number of input tokens (ignoring truncation): 233651\n",
      "Mean: 106.205\n",
      "Median: 128.0\n",
      "Standard deviation: 32.21301646144699\n",
      "Minimum: 20\n",
      "Maximum: 128\n",
      "Loading 2200 examples from data/JS-22k/test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:02<00:00, 1000.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 281600\n",
      "Total number of truncated examples: 1282\n",
      "Total number of input tokens (ignoring truncation): 232595\n",
      "Mean: 105.725\n",
      "Median: 128.0\n",
      "Standard deviation: 32.41501212962346\n",
      "Minimum: 12\n",
      "Maximum: 128\n",
      "Loading 2200 examples from data/JS-22k/test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:02<00:00, 1087.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 281600\n",
      "Total number of truncated examples: 1333\n",
      "Total number of input tokens (ignoring truncation): 233651\n",
      "Mean: 106.205\n",
      "Median: 128.0\n",
      "Standard deviation: 32.21301646144699\n",
      "Minimum: 20\n",
      "Maximum: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 400/734 [11:11<09:20,  1.68s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m test_posthoc_dataset \u001b[39m=\u001b[39m CustomPostHocDataset(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/test.json\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(DATA_FOLDER), MODEL_TYPE, tokenizer, MAX_LENGTH)\n\u001b[1;32m      3\u001b[0m test_posthoc_dataloader \u001b[39m=\u001b[39m DataLoader(test_posthoc_dataset, batch_size\u001b[39m=\u001b[39mBATCH_SIZE, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, collate_fn\u001b[39m=\u001b[39mposthoc_collate_fn)\n\u001b[0;32m----> 4\u001b[0m test_posthoc_scores \u001b[39m=\u001b[39m evaluate_posthoc(test_posthoc_dataloader)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m      7\u001b[0m yhat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m new \u001b[39m-\u001b[39m old \u001b[39m>\u001b[39m best_cutoff \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m old, new, _ \u001b[39min\u001b[39;00m test_posthoc_scores])\n",
      "Cell \u001b[0;32mIn[18], line 27\u001b[0m, in \u001b[0;36mevaluate_posthoc\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     25\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     26\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 27\u001b[0m     old_probs \u001b[39m=\u001b[39m my_model(old_input_ids, old_attention_mask, labels)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     28\u001b[0m     new_probs \u001b[39m=\u001b[39m my_model(new_input_ids, new_attention_mask, labels)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     29\u001b[0m \u001b[39mfor\u001b[39;00m old, new, label \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(old_probs, new_probs, labels):\n\u001b[1;32m     30\u001b[0m     \u001b[39m# Store the scores for the positive label\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/thesis/master-project/notebooks/lib/models.py:56\u001b[0m, in \u001b[0;36mget_model.<locals>.CodeBERTBasedModel.forward\u001b[0;34m(self, input_ids, attention_mask, labels, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 56\u001b[0m     encoder_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(input_ids, attention_mask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     57\u001b[0m     cls_encoded \u001b[39m=\u001b[39m encoder_out[\u001b[39m0\u001b[39m][:, \u001b[39m0\u001b[39m, :]  \u001b[39m# take <s> token (equiv. to [CLS])\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(cls_encoded)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:852\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    843\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    845\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    846\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    847\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    850\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    851\u001b[0m )\n\u001b[0;32m--> 852\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    853\u001b[0m     embedding_output,\n\u001b[1;32m    854\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    855\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    856\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    857\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    858\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    859\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    860\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    861\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    862\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    863\u001b[0m )\n\u001b[1;32m    864\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    865\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:527\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    518\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    520\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    528\u001b[0m         hidden_states,\n\u001b[1;32m    529\u001b[0m         attention_mask,\n\u001b[1;32m    530\u001b[0m         layer_head_mask,\n\u001b[1;32m    531\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    532\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    533\u001b[0m         past_key_value,\n\u001b[1;32m    534\u001b[0m         output_attentions,\n\u001b[1;32m    535\u001b[0m     )\n\u001b[1;32m    537\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:453\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    450\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    451\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 453\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    454\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    455\u001b[0m )\n\u001b[1;32m    456\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    458\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 237\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:465\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> 465\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    466\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    467\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:364\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    363\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 364\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate_act_fn(hidden_states)\n\u001b[1;32m    365\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/activations.py:78\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact(\u001b[39minput\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate best_cutoff on test set\n",
    "test_posthoc_dataset = CustomPostHocDataset('{}/test.json'.format(DATA_FOLDER), MODEL_TYPE, tokenizer, MAX_LENGTH)\n",
    "test_posthoc_dataloader = DataLoader(test_posthoc_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=posthoc_collate_fn)\n",
    "test_posthoc_scores = evaluate_posthoc(test_posthoc_dataloader)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "yhat = np.array([1 if new - old > best_cutoff else 0 for old, new, _ in test_posthoc_scores])\n",
    "y = np.array([label for _, _, label in test_posthoc_scores])\n",
    "acc = sklearn.metrics.accuracy_score(y, yhat)\n",
    "f1 = sklearn.metrics.f1_score(y, yhat)\n",
    "precision = sklearn.metrics.precision_score(y, yhat)\n",
    "recall = sklearn.metrics.recall_score(y, yhat)\n",
    "confusion = sklearn.metrics.confusion_matrix(y, yhat)\n",
    "\n",
    "print(f\"Test accuracy: {acc}\")\n",
    "print(f\"Test F1: {f1}\")\n",
    "print(f\"Test precision: {precision}\")\n",
    "print(f\"Test recall: {recall}\")\n",
    "print(f\"Test confusion matrix:\")\n",
    "print(confusion)\n",
    "print('Confusion matrix of test set')\n",
    "tn, fp, fn, tp = confusion.ravel()\n",
    "print(f\"false positives: {fp}, false negatives: {fn}\")\n",
    "# Log to wandb\n",
    "if USE_WANDB:\n",
    "    wandb.log({\n",
    "        'posthoc_test_acc': acc,\n",
    "        'posthoc_test_f1': f1,\n",
    "        'posthoc_test_precision': precision,\n",
    "        'posthoc_test_recall': recall,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "wandb.finish()\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a039f0b1bebafebeb17a7df39f3cb9e08c871cbba42b919bd83805750af3b3a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
